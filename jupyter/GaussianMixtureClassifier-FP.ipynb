{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the dataset\n",
    "\n",
    "N = 3000\n",
    "norm00 = np.random.multivariate_normal([0,0], [[.05,0],[0,.05]], size=N//2)\n",
    "norm11 = np.random.multivariate_normal([1.,1.], [[.05,0],[0,.05]], size=N//2)\n",
    "labels_np = np.int64(np.hstack((np.zeros(norm00.shape[0]),\n",
    "                             np.ones(norm11.shape[0])\n",
    "                            )))\n",
    "features_np = np.float32(np.vstack((norm00, norm11)))\n",
    "data = np.hstack([features_np, labels_np[:,None]])\n",
    "np.random.shuffle(data)\n",
    "\n",
    "labels_np, features_np = np.intp(data[:,-1]), np.float32(data[:,:2])\n",
    "\n",
    "cut = N * 2 // 3\n",
    "features_training, labels_training = features_np[:cut], labels_np[:cut]\n",
    "features_testing, labels_testing = features_np[cut:], labels_np[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the fingerprints\n",
    "FP_NUM = 4\n",
    "EPS = 0.06\n",
    "alpha = 0.25\n",
    "beta = 0.75\n",
    "NUM_CLASS = 2\n",
    "dx = (np.random.rand(FP_NUM, features_np.shape[1]) -.5)*2*EPS\n",
    "\n",
    "dy_train = -np.ones((NUM_CLASS, NUM_CLASS))*alpha #2 is number of classes\n",
    "for i in range(NUM_CLASS):\n",
    "    dy_train[i,i] = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build graph\n",
    "features = tf.placeholder(features_np.dtype, [None, 2])\n",
    "labels = tf.placeholder(labels_np.dtype, [None])\n",
    "fp_dx = tf.placeholder(features_np.dtype, [FP_NUM, None, 2])\n",
    "fp_dy = tf.constant(dy_train)\n",
    "\n",
    "labels_oh = tf.one_hot(labels, NUM_CLASS)\n",
    "\n",
    "fc1 = tf.layers.Dense(units=200, activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.truncated_normal)\n",
    "fc2 = tf.layers.Dense(units=200, activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.truncated_normal)\n",
    "logits_out = tf.layers.Dense(units=NUM_CLASS, activation=None, kernel_initializer=tf.initializers.truncated_normal)\n",
    "\n",
    "# real data tensors\n",
    "normed_x = features - tf.reduce_mean(features)\n",
    "logits = logits_out(fc2(fc1(features)))\n",
    "loss_vanilla = tf.losses.softmax_cross_entropy(labels_oh, logits)\n",
    "probs = tf.nn.softmax(logits)\n",
    "classification = tf.argmax(probs, axis=1)\n",
    "correct_classification = tf.equal(classification, labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_classification, tf.float32))\n",
    "\n",
    "\n",
    "# fingerprint tensors\n",
    "perturbed = features + fp_dx\n",
    "fp_logits = logits_out(fc2(fc1(perturbed)))\n",
    "\n",
    "FxDx = logits/(tf.norm(logits, axis=1)[:,None])[None,:,:] - fp_logits/tf.norm(fp_logits, axis=1)[:,None]\n",
    "Dy = tf.gather(fp_dy, labels)\n",
    "Dy = tf.stack([Dy]*FP_NUM)\n",
    "\n",
    "loss_fp = tf.losses.mean_squared_error(Dy, FxDx)\n",
    "loss = loss_vanilla + loss_fp\n",
    "\n",
    "train = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_dict = {features:features_training, labels:labels_training, fp_dx:dx[:,np.newaxis,:]}\n",
    "testing_dict = {features:features_testing, labels:labels_testing, fp_dx:dx[:,np.newaxis,:]}\n",
    "\n",
    "for epoch in range(1000):\n",
    "    sess.run([train], feed_dict=training_dict)\n",
    "    test_data_loss, test_fp_loss, test_loss, test_acc = sess.run(\n",
    "        [loss_vanilla, loss_fp, loss, accuracy],\n",
    "        feed_dict=testing_dict\n",
    "    )\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch', epoch, 'data loss %.6f fp loss %.6f total loss: %.6f accuracy: %.3f' %\\\n",
    "              (test_data_loss, test_fp_loss, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-1:2:0.005, -1:2:0.005]\n",
    "prob_c = sess.run(probs > 0.5, feed_dict={features:np.dstack((x,y)).reshape((-1, 2))})[:,1]\n",
    "plt.contourf(x, y, prob_c.reshape(x.shape), cmap='gray');\n",
    "plt.colorbar()\n",
    "plt.scatter(features_testing[:,0], features_testing[:,1], c = labels_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-1:2:0.005, -1:2:0.005]\n",
    "test_fp = sess.run(FxDx, feed_dict={features:np.dstack((x,y)).reshape((-1, 2)), fp_dx:dx[:,None,:]})\n",
    "imputed_labels = np.intp(np.linalg.norm(np.dstack((x,y)).reshape(-1,2) - np.array([0,0]), axis=1) >\\\n",
    "                    np.linalg.norm(np.dstack((x,y)).reshape(-1,2) - np.array([1,1]), axis=1))\n",
    "dissimilarities = np.array(\n",
    "    [\n",
    "        check_fp(test_fp[:,i,:], imputed_labels[i], dy_train)\n",
    "            for i in range(test_fp.shape[1])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(x, y, dissimilarities.reshape(x.shape) > 0.6, cmap='gray');\n",
    "# plt.colorbar()\n",
    "plt.scatter(features_testing[:,0], features_testing[:,1], c = labels_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fp(fxdx, label, dy):\n",
    "    return np.sum((fxdx - dy[label])**2)/fxdx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY FINGERPRINTS\n",
    "mini_dict = {\n",
    "    features:features_testing[:10],\n",
    "    labels:labels_testing[:10],\n",
    "    fp_dx:dx[:,np.newaxis,:]\n",
    "}\n",
    "fxdx, dy = sess.run([FxDx, Dy], feed_dict=mini_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "print(dy[:,i])\n",
    "print(fxdx[:,i])\n",
    "print(labels_testing[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
