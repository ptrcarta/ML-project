{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "\n",
    "N = 2000\n",
    "norm00 = np.random.multivariate_normal([-3, -3], [[1, 0], [0, 1]], size=N // 2)\n",
    "norm11 = np.random.multivariate_normal([3, 3], [[1, 0], [0, 1]], size=N // 2)\n",
    "labels_np = np.int64(np.hstack((np.zeros(norm00.shape[0]),\n",
    "                                np.ones(norm11.shape[0])\n",
    "                                )))\n",
    "features_np = np.float32(np.vstack((norm00, norm11)))\n",
    "data = np.hstack([features_np, labels_np[:, None]])\n",
    "np.random.shuffle(data)\n",
    "\n",
    "labels_np, features_np = np.intp(data[:, -1]), np.float32(data[:, :2])\n",
    "\n",
    "cut = N * 2 // 3\n",
    "features_training_np, labels_training_np = features_np[:cut], labels_np[:cut]\n",
    "features_testing_np, labels_testing_np = features_np[cut:], labels_np[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the fingerprints\n",
    "FP_NUM = 4\n",
    "EPS = 0.06\n",
    "alpha = 0.25\n",
    "beta = 0.75\n",
    "NUM_CLASS = 2\n",
    "dx = (np.random.rand(FP_NUM, features_np.shape[1]) - .5) * 2 * EPS\n",
    "\n",
    "dy_train = -np.ones((NUM_CLASS, NUM_CLASS)) * alpha  # 2 is number of classes\n",
    "for i in range(NUM_CLASS):\n",
    "    dy_train[i, i] = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "def nn(input_shape):\n",
    "    model = tf.keras.Sequential((\n",
    "        tf.keras.layers.Dense(200, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASS, activation=None)))  # not Softmax\n",
    "    model.build()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "features_tf = tf.placeholder(features_np.dtype, [None, 2])\n",
    "labels = tf.placeholder(labels_np.dtype, [None])\n",
    "dx_tf = tf.placeholder(features_np.dtype, [FP_NUM, None, 2])\n",
    "dy_tf = tf.constant(dy_train, dtype=dx_tf.dtype)\n",
    "\n",
    "labels_oh = tf.one_hot(labels, NUM_CLASS)\n",
    "\n",
    "\n",
    "logits = nn(features_np.shape)(features_tf)\n",
    "\n",
    "loss_vanilla = tf.losses.softmax_cross_entropy(labels_oh, logits)\n",
    "probs = tf.nn.softmax(logits)\n",
    "classification = tf.argmax(probs, axis=1)\n",
    "correct_classification = tf.equal(classification, labels)\n",
    "# TODO MAYBE USE tf.accuracy?\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_classification, tf.float32))\n",
    "\n",
    "fp_logits = nn(features_np.shape)(features_tf + dx_tf)\n",
    "\n",
    "\n",
    "def normalize(fp_logits):\n",
    "    return fp_logits / tf.norm(fp_logits, axis=1)[:, None]\n",
    "\n",
    "\n",
    "# TODO PIETRO -> orderd should be inverted..\n",
    "FxDx = normalize(logits) - normalize(fp_logits)\n",
    "\n",
    "\n",
    "Dy = tf.gather(dy_tf, labels)\n",
    "Dy = tf.stack([Dy] * FP_NUM)\n",
    "\n",
    "loss_fp = tf.losses.mean_squared_error(Dy, FxDx)\n",
    "loss = loss_vanilla + loss_fp\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "training_dict = {features_tf: features_training_np,\n",
    "                 labels: labels_training_np,\n",
    "                 dx_tf: dx[:, np.newaxis, :]}\n",
    "\n",
    "testing_dict = {features_tf: features_testing_np,\n",
    "                labels: labels_testing_np,\n",
    "                dx_tf: dx[:, np.newaxis, :]}\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    sess.run([train], feed_dict=training_dict)\n",
    "    test_data_loss, test_fp_loss, test_loss, test_acc = sess.run(\n",
    "        [loss_vanilla, loss_fp, loss, accuracy],\n",
    "        feed_dict=testing_dict\n",
    "    )\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch', epoch, 'data loss %.6f fp loss %.6f total loss: %.6f accuracy: %.3f' % (\n",
    "            test_data_loss, test_fp_loss, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-8:8:0.1, -8:8:0.1]\n",
    "prob_c = sess.run(probs > 0.5, feed_dict={\n",
    "                  features_tf: np.dstack((x, y)).reshape((-1, 2))})[:, 1]\n",
    "plt.contourf(x, y, prob_c.reshape(x.shape), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.scatter(features_testing_np[:, 0],\n",
    "            features_testing_np[:, 1], c=labels_testing_np)\n",
    "for i in range(FP_NUM):\n",
    "    plt.arrow(-3, -3, 100 * dx[i, 0], 100 * dx[i, 1], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.expand_dims(FxDx, 2)\n",
    "t2 = t1 - dy_tf\n",
    "t3 = t2 ** 2\n",
    "t4 = tf.reduce_sum(t3, axis=-1)\n",
    "t5 = (1.0 / FP_NUM) * tf.sqrt(t4)\n",
    "t6 = tf.transpose(t5, [1, 2, 0])\n",
    "t7 = tf.reduce_sum(t6, axis=-1)\n",
    "t8 = tf.reduce_min(t7, axis=-1)\n",
    "\n",
    "x, y = np.mgrid[-8:8:0.05, -8:8:0.05]\n",
    "dissimilarities = sess.run(t8, feed_dict={features_tf: np.dstack(\n",
    "    (x, y)).reshape((-1, 2)), dx_tf: dx[:, None, :]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(x, y, dissimilarities.reshape(x.shape), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.scatter(features_testing_np[:, 0],\n",
    "            features_testing_np[:, 1], c=labels_testing_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY FINGERPRINTS\n",
    "\n",
    "mini_dict = {\n",
    "    features_tf: features_testing_np[:10],\n",
    "    labels: labels_testing_np[:10],\n",
    "    dx_tf: dx[:, np.newaxis, :]\n",
    "}\n",
    "fxdx, dy = sess.run([FxDx, Dy], feed_dict=mini_dict)\n",
    "\n",
    "\n",
    "i = 6\n",
    "print(dy[:, i])\n",
    "print(fxdx[:, i])\n",
    "print(labels_testing_np[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
