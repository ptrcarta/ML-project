{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE THE DATA\n",
    "\n",
    "size = 1000\n",
    "ball_0 = multivariate_normal(mean=[-3,-3], cov=np.eye(2), size=size)\n",
    "ball_1 = multivariate_normal(mean=[3,3], cov=np.eye(2), size=size)\n",
    "\n",
    "plt.scatter(ball_0[:,0], ball_0[:,1])\n",
    "plt.scatter(ball_1[:,0], ball_1[:,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_one_hot(labels):\n",
    "    enc = OneHotEncoder(categories='auto', sparse=False)\n",
    "    enc.fit(labels)\n",
    "    return enc.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = [0.0] * size \n",
    "y_1 = [1.0] * size\n",
    "y = np.concatenate([y_0, y_1])[:,np.newaxis]\n",
    "X = np.concatenate([ball_0, ball_1])\n",
    "y = label_to_one_hot(y)\n",
    "\n",
    "data = np.hstack([X,y])\n",
    "print(data.shape)\n",
    "\n",
    "# permutate random\n",
    "np.random.shuffle(data)\n",
    "X = data[:,0:2]\n",
    "y = data[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 1500\n",
    "\n",
    "x_train = X[0:NUM_TRAIN,:]\n",
    "x_test = X[NUM_TRAIN:,:]\n",
    "\n",
    "y_train = y[0:NUM_TRAIN]\n",
    "\n",
    "y_test = y[NUM_TRAIN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FP = 4\n",
    "FP_EPS = 0.1\n",
    "NUM_CLASSES = 2\n",
    "NUM_FEATURES = 2\n",
    "\n",
    "# dx is input distortion, number of dxs is equal to number of unique fingerprints\n",
    "fp_dx = [np.random.rand(1, NUM_FEATURES) * FP_EPS for i in range(NUM_FP)]\n",
    "\n",
    "# In paper, dy's are the same for each dx, so dy, and they are distortion to logits\n",
    "# since logits dimension is NUM_CLASSES and we need NUM_CLASSES dy definitions (one\n",
    "# dy for each class), dy dimension will be NUM_CLASSESS x NUM_CLASSES\n",
    "\n",
    "# Details in paper, section 2.3 (choosing dys)\n",
    "fp_dy = -0.2357*np.ones((NUM_CLASSES, NUM_CLASSES))\n",
    "for cl in range(NUM_CLASSES):\n",
    "    fp_dy[cl, cl] = 0.7\n",
    "\n",
    "print('fp_dx')\n",
    "print(fp_dx)\n",
    "print('fp_dy')\n",
    "print(fp_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fingerprint training example/label pairs\n",
    "\n",
    "x_train_fp = np.zeros((NUM_FP, NUM_TRAIN, NUM_FEATURES), dtype=np.float32)\n",
    "for i in range(NUM_FP):\n",
    "    x_train_fp[i] = x_train + fp_dx[i]\n",
    "\n",
    "y_train_fp = np.zeros((NUM_FP, NUM_TRAIN, NUM_CLASSES), dtype=np.float32)\n",
    "for i in range(NUM_FP):\n",
    "    for j in range(NUM_TRAIN):\n",
    "        y_train_fp[i][j] = fp_dy[np.argwhere(y_train[j] == float(1))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0:5])\n",
    "print(y_train_fp[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tf = tf.placeholder(tf.float32, shape=(None, NUM_FEATURES), name=\"x\")\n",
    "y_tf = tf.placeholder(tf.float32, shape=(None, NUM_CLASSES), name=\"y\")\n",
    "\n",
    "fp_shape_tenor = tf.stack([\n",
    "    tf.constant(NUM_FP),\n",
    "    tf.shape(x_tf)[0],\n",
    "    tf.constant(NUM_FEATURES)\n",
    "])\n",
    "\n",
    "fp_shape_tenor\n",
    "x_fp_tf = tf.placeholder(tf.float32, shape=fp_shape_tenor, name=\"x_fp\")\n",
    "x_fp_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tf = tf.placeholder(tf.float32, shape=(None, NUM_FEATURES), name=\"x\")\n",
    "y_tf = tf.placeholder(tf.float32, shape=(None, NUM_CLASSES), name=\"y\")\n",
    "\n",
    "x_fp_tf = tf.placeholder(tf.float32, shape=(NUM_FP, None, NUM_FEATURES), name=\"x_fp\")\n",
    "y_fp_tf = tf.placeholder(tf.float32, shape=(NUM_FP, None, NUM_CLASSES), name=\"y_fp\")\n",
    "\n",
    "hidden1 = tf.layers.Dense(units=200, activation=tf.nn.relu, name=\"hidden1\")\n",
    "hidden2 = tf.layers.Dense(units=200, activation=tf.nn.relu, name=\"hidden2\")\n",
    "out = tf.layers.Dense(units=NUM_CLASSES, activation=tf.nn.relu)\n",
    "\n",
    "y_logits = hidden1(x_tf)\n",
    "y_logits = hidden2(y_logits)\n",
    "y_logits = out(y_logits)\n",
    "y_logits_normed = y_logits / (tf.stack([tf.norm(y_logits, axis=1)] * NUM_CLASSES, axis=1) + 0.0001)\n",
    "y_preds = tf.nn.softmax(y_logits)\n",
    "\n",
    "y_fp_preds = []\n",
    "for i in range(NUM_FP):\n",
    "    cur_x_fp = x_fp_tf[i]\n",
    "    cur_y_fp = hidden1(cur_x_fp)\n",
    "    cur_y_fp = hidden2(cur_y_fp)\n",
    "    cur_y_fp = out(cur_y_fp)\n",
    "    cur_y_fp = cur_y_fp / (tf.stack([tf.norm(cur_y_fp, axis=1)] * NUM_CLASSES, axis=1) + 0.0001)\n",
    "    y_fp_preds.append(cur_y_fp)\n",
    "y_fp_preds = tf.stack(y_fp_preds)\n",
    "\n",
    "loss_vanilla = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_tf, logits=y_logits)\n",
    "loss_fp = tf.losses.mean_squared_error(y_fp_preds - tf.stack([y_logits_normed] * 4), y_fp_tf)\n",
    "loss = loss_vanilla + 1.0 * loss_fp\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    if True:\n",
    "        _, loss_value = sess.run((train, loss), feed_dict={\n",
    "          x_tf: x_train, y_tf: y_train, x_fp_tf: x_train_fp, y_fp_tf: y_train_fp\n",
    "        })\n",
    "        print(loss_value)\n",
    "    if False:\n",
    "        lol = sess.run(y_fp_preds - tf.stack([y_logits_normed] * 4), feed_dict={\n",
    "              x_tf: x_train, y_tf: y_train, x_fp_tf: x_train_fp, y_fp_tf: y_train_fp\n",
    "            })\n",
    "        print(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = sess.run(y_pred, feed_dict={x_tf: x_test})\n",
    "final_preds = final_preds.squeeze(axis=1)\n",
    "final_preds = final_preds <= 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x_test[:,0], y=x_test[:,1], hue=final_preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield x\n",
    "        x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid(minX, minY, maxX, maxY, delta):\n",
    "    pts = []\n",
    "    for x in frange(minX, maxX, delta):\n",
    "        for y in frange(minY, maxY, delta):\n",
    "            pts.append([x, y])\n",
    "    return np.array(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = generate_grid(-5, -5, 5, 5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
